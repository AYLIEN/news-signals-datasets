{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook to perform TABSA (Targeted Aspect Based Sentiment Analysis) on News-Data (to know how to get news data, please refer to the **raw_news_sentiment.ipynb** notebook).\n",
    "\n",
    "This is using PyAbsa library, Please keep in mind that the PyAbsa library is prone to many dependency issues, I have tried to cover the necessary installations in this jupyter notebook, however depending on your installation, you may need to resolve dependency and version errors.\n",
    "\n",
    "Also you need to have a list of terms that you are actively looking for in the data for it to work properly.\n",
    "\n",
    "[PyAbsa Github](https://github.com/yangheng95/PyABSA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import news_signals\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses yfinance library to get financial data, then classifies the trend of the market trend movement by checking if the price has moved by a certain percentage over a certain time period.\n",
    "\n",
    "Currently it is set for TSLA stock (Tesla) for the year 2023, over a 3 day rolling window of 3% threshold, i.e it gets financial data for Tesla stock for the entire year of 2023, it splits it into 3 day rolling windows, and gives classification of *+1 for upward trend, 0 for neutral (within threshold), -1 for a downward trend*, so if in 3 days, the stock has moved up or down more than 3%, it gets a +1 or -1 classification respectively, otherwise it gets a neutral 0.\n",
    "\n",
    "\n",
    "Modify **ticker** to whichever stock you wish to get data for (e.g TSLA,AAPL,JPM). **start_date** and **end_date** to specify the time period of the overall financial data, **window_size** for the rolling window days and **percent_change** to change the decimal percentage value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"TSLA\"            # Change ticker if needed\n",
    "start_date = \"2023-01-01\"    # Start date for historical data\n",
    "end_date = \"2023-12-31\"      # End date for historical data\n",
    "window_size = 3            # 3-day rolling window\n",
    "\n",
    "# Download daily stock data\n",
    "data = yf.download(ticker, start=start_date, end=end_date)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "def classify_window(window):\n",
    "    \"\"\"\n",
    "        +1 if cumulative return > %change and > volatility  (upward trend)\n",
    "        -1 if cumulative return < -%change and < -volatility (downward trend)\n",
    "         0 otherwise (neutral)\n",
    "    \"\"\"\n",
    "    first_open = float(window['Open'].iloc[0])\n",
    "    last_close = float(window['Close'].iloc[-1])\n",
    "    cumulative_return = (last_close - first_open) / first_open\n",
    "    daily_returns = (window['Close'] - window['Open']) / window['Open']\n",
    "    volatility = float(daily_returns.std())\n",
    "    \n",
    "    if cumulative_return > 0.03 and cumulative_return > volatility:\n",
    "        return 1\n",
    "    elif cumulative_return < -0.03 and cumulative_return < -volatility:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Apply a rolling window to classify the trend for each period\n",
    "trend_results = []\n",
    "dates = []\n",
    "for i in range(window_size - 1, len(data)):\n",
    "    window = data.iloc[i - window_size + 1 : i + 1]\n",
    "    trend = classify_window(window)\n",
    "    trend_results.append(trend)\n",
    "    dates.append(data.index[i])\n",
    "\n",
    "# Create a DataFrame with the trend classifications (using the last day of each window as the index)\n",
    "rolling_trend_df = pd.DataFrame({'Trend': trend_results}, index=dates)\n",
    "print(rolling_trend_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can run this cell to check distribution of financial trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution = rolling_trend_df['Trend'].value_counts(normalize=True) * 100\n",
    "print(\"Class Distribution (Percentage):\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Plot the class distribution as percentages\n",
    "class_distribution.plot(kind='bar', color=['red', 'blue', 'green'])\n",
    "plt.title('Class Distribution of Trends (Percentage)')\n",
    "plt.xlabel('Trend')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few necessary imports, however dependent on setup to resolve dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyabsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.29.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform TABSA on our dataset.\n",
    "\n",
    "**target_aspects** : Is a list of terms towards who we are checking for sentiments, feel free to modify for your use-case\n",
    "\n",
    "Sentiment mapping:\n",
    "\n",
    "**Positive -> 1**\n",
    "\n",
    "**Neutral -> 0**\n",
    "\n",
    "**Negative -> -1**\n",
    "\n",
    "We then attach the sentiments of each term to our financial trend data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pyabsa import APCCheckpointManager\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Part 1: Load ABSA Model for Analysis\n",
    "# =============================\n",
    "\n",
    "# Load the Aspect Polarity Classification model\n",
    "apc_model = APCCheckpointManager.get_sentiment_classifier(\n",
    "    checkpoint=\"English\",\n",
    "    dataset=\"None\"\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_aspect_sentiments(text):\n",
    "    \"\"\"\n",
    "    Extract sentiment scores for Tesla-related aspects.\n",
    "    Sentiment mapping:\n",
    "    - Positive -> 1\n",
    "    - Neutral -> 0\n",
    "    - Negative -> -1\n",
    "    \"\"\"\n",
    "    target_aspects = [\n",
    "        \"production\", \"delivery\", \"earnings\", \"innovation\",\n",
    "        \"autopilot\", \"leadership\", \"supply chain\", \"sustainability\"\n",
    "    ]\n",
    "    aspect_scores = {aspect: 0.0 for aspect in target_aspects}\n",
    "    counts = {aspect: 0 for aspect in target_aspects}\n",
    "\n",
    "    # Ensure input is a valid string\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return aspect_scores  # Return default zero scores if input is invalid\n",
    "\n",
    "    try:\n",
    "        # Run inference\n",
    "        results = apc_model.predict(text, print_result=False)\n",
    "\n",
    "        #  Debugging: Print results to inspect the structure\n",
    "        print(f\"DEBUG: PyABSA Output -> {results}\")\n",
    "\n",
    "        # Ensure results is in list format\n",
    "        if isinstance(results, dict):  \n",
    "            results = [results]  \n",
    "\n",
    "        if not isinstance(results, list):\n",
    "            print(f\"Skipping unexpected format: {results}\")\n",
    "            return aspect_scores\n",
    "\n",
    "        for result in results:\n",
    "            if isinstance(result, dict):\n",
    "                aspect_texts = result.get(\"aspect\", [])\n",
    "                sentiments = result.get(\"sentiment\", [])\n",
    "\n",
    "                # Ensure both are lists\n",
    "                if not isinstance(aspect_texts, list):\n",
    "                    aspect_texts = [aspect_texts]\n",
    "                if not isinstance(sentiments, list):\n",
    "                    sentiments = [sentiments]\n",
    "\n",
    "                for aspect_text, sentiment in zip(aspect_texts, sentiments):\n",
    "                    aspect_text = aspect_text.lower()\n",
    "                    sentiment = sentiment.lower()\n",
    "\n",
    "                    score = {\"positive\": 1, \"negative\": -1, \"neutral\": 0}.get(sentiment, 0)\n",
    "\n",
    "                    for target in target_aspects:\n",
    "                        if target in aspect_text:\n",
    "                            aspect_scores[target] += score\n",
    "                            counts[target] += 1\n",
    "            else:\n",
    "                print(f\"Skipping unexpected format: {result}\")\n",
    "                continue  \n",
    "\n",
    "        # Average scores for aspects mentioned multiple times\n",
    "        for target in target_aspects:\n",
    "            if counts[target] > 0:\n",
    "                aspect_scores[target] /= counts[target]\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"RuntimeError in PyABSA: {e}\")\n",
    "        return aspect_scores\n",
    "\n",
    "    return aspect_scores\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Part 2: Process News Data and Extract Sentiments\n",
    "# =============================\n",
    "\n",
    "news_df = pd.read_csv(\"entity_news_processed_azure_reduced.csv\")\n",
    "news_df[\"published_at\"] = pd.to_datetime(news_df[\"published_at\"]).dt.tz_convert(None)\n",
    "news_df[\"Processed_Article\"] = news_df[\"Processed_Article\"].fillna(\"\").astype(str)\n",
    "\n",
    "news_df[\"Aspect_Sentiments\"] = news_df[\"Processed_Article\"].apply(extract_aspect_sentiments)\n",
    "aspect_scores_df = pd.json_normalize(news_df[\"Aspect_Sentiments\"])\n",
    "news_df = pd.concat([news_df, aspect_scores_df], axis=1)\n",
    "\n",
    "\n",
    "rolling_trend_df_reset = rolling_trend_df.reset_index().rename(columns={'index': 'Date'})\n",
    "rolling_trend_df_reset[\"Date\"] = pd.to_datetime(rolling_trend_df_reset[\"Date\"])\n",
    "rolling_trend_df_reset = rolling_trend_df_reset.sort_values(\"Date\")\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Part 4: Attach Sentiments to Financial Data\n",
    "# =============================\n",
    "\n",
    "FINANCE_START_DATE = pd.to_datetime(start_date)\n",
    "ATTACHED_ASPECT_FEATURES = []\n",
    "ASPECTS = [\n",
    "    \"production\", \"delivery\", \"earnings\", \"innovation\",\n",
    "    \"autopilot\", \"leadership\", \"supply chain\", \"sustainability\"\n",
    "]\n",
    "\n",
    "prev_date = FINANCE_START_DATE\n",
    "\n",
    "for current_date in rolling_trend_df_reset[\"Date\"]:\n",
    "    mask = (news_df[\"published_at\"] >= prev_date) & (news_df[\"published_at\"] < current_date)\n",
    "    window_news = news_df[mask]\n",
    "\n",
    "    if not window_news.empty:\n",
    "        avg_scores = window_news[ASPECTS].mean().to_dict()\n",
    "    else:\n",
    "        avg_scores = {aspect: 0.0 for aspect in ASPECTS}\n",
    "\n",
    "    ATTACHED_ASPECT_FEATURES.append(avg_scores)\n",
    "    prev_date = current_date\n",
    "\n",
    "aspect_features_df = pd.DataFrame(ATTACHED_ASPECT_FEATURES)\n",
    "final_financial_df = pd.concat([rolling_trend_df_reset.reset_index(drop=True), aspect_features_df], axis=1)\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Part 5: Save Final Data\n",
    "# =============================\n",
    "\n",
    "OUTPUT_FILENAME = \"financial_data_with_aspect_sentiments.csv\"\n",
    "final_financial_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "\n",
    "print(f\"Saved updated financial data with aspect sentiment features to {OUTPUT_FILENAME}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-signals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
