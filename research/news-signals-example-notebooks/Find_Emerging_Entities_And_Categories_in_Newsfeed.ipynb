{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ce78c3",
   "metadata": {},
   "source": [
    "## This notebook shows how news-signals makes exploratory data analysis on newsfeeds easy\n",
    "\n",
    "In this example, we have a signal with a feed of stories, we want to process the stories and discover how narratives evolved over time.\n",
    "\n",
    "Let's look at the recent Silicon Valley Bank collapse.\n",
    "In the first pass, let's just look at the top entities and categories in this signal and how they changed over time, leading up to the Silicon Valley Bank collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed if news_signals is already installed\n",
    "# you might see a pip version error but it's grand, don't worry\n",
    "!pip install -q news_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97eb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from news_signals import signals, signals_dataset, newsapi, wikidata_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea72e5b",
   "metadata": {},
   "source": [
    "If you want to build a signal yourself, first get a NewsAPI account, then the cell below shows how\n",
    "(uncomment the commented code).\n",
    "\n",
    "However, for the purposes of this example, we've already created a signal and uploaded it to the Google Drive, so you don't need a NewsAPI account, and the example should just run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dabde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's setup the entity we want to work with\n",
    "entity_name = 'Silicon Valley Bank'\n",
    "\n",
    "\n",
    "# Build a new signal - see the README at https://github.com/AYLIEN/news-signals-datasets \n",
    "# for how to set up a NewsAPI trial account. \n",
    "# entity_id_candidates = wikidata_utils.search_wikidata(entity_name)\n",
    "# test_entity = entity_id_candidates[0]\n",
    "\n",
    "# # cool, now let's create a signal\n",
    "# signal = signals.AylienSignal(\n",
    "#     name=test_entity['label'],\n",
    "#     params={\"entity_ids\": [test_entity['id']]}\n",
    "# )\n",
    "\n",
    "# # let's instantiate our signal for the time period we care about\n",
    "# # investigation period\n",
    "# start = '2022-10-01'\n",
    "# end = '2023-03-18'\n",
    "\n",
    "# signal = signal(start, end).sample_stories_in_window(start, end, num_stories=50)\n",
    "\n",
    "# output_dir = Path(f'example_signals/{entity_name}_{start}_{end}')\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# signal.save(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a425832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the saved signal from Google Drive\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "cache_dir = Path('tmp/saved_signals')\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "dataset_path = 'https://drive.google.com/drive/folders/1RgstgaORO0OEdwUIQ0Bj997JVQulZo7n?usp=share_link'\n",
    "\n",
    "signal = list(\n",
    "    signals_dataset.SignalsDataset.load(dataset_path, cache_dir=cache_dir)\n",
    "    .signals.values())[0]\n",
    "signal.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb84d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sfs(aylien_entities):\n",
    "    \"\"\"\n",
    "    A utility function that collects all entity surface forms from the \n",
    "    'entities' field of an Aylien NewsAPI story. \n",
    "    \"\"\"\n",
    "    sfs = Counter()\n",
    "    for e in aylien_entities:\n",
    "        for sf in e['title']['surface_forms'] + e['body']['surface_forms']:\n",
    "            sfs.update([sf['text']])\n",
    "    return sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08648c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = OrderedDict()\n",
    "category_diffs = OrderedDict()\n",
    "category_probs = OrderedDict()\n",
    "\n",
    "\n",
    "# scroll through all the stories in a feed and check for surprises in entities or categories\n",
    "prev_date = None\n",
    "for date, stories in signal['stories'].items():\n",
    "    date = str(date.date())\n",
    "\n",
    "    # CATEGORIES\n",
    "    category_counts[date] = Counter(c['label'] for s in stories for c in s['categories'] if 'label' in c)\n",
    "\n",
    "    # ENTITIES\n",
    "#     category_counts[date] = Counter(sf_ for s in stories \n",
    "#                                     for sf_ in \n",
    "#                                     collect_sfs(s['entities']).keys())\n",
    "\n",
    "    category_probs[date] = \\\n",
    "        OrderedDict((c, count / len(stories))\n",
    "                    for c, count in category_counts[date].most_common())\n",
    "    \n",
    "    diffs = OrderedDict()\n",
    "    if prev_date is not None:\n",
    "        for c in category_probs[date]:\n",
    "            if c in category_probs[prev_date]:\n",
    "                diff = category_probs[date][c] - category_probs[prev_date][c]\n",
    "            else:\n",
    "                diff = category_probs[date][c]\n",
    "            diffs[c] = diff\n",
    "\n",
    "    category_diffs[date] = OrderedDict((c, d) for c, d in sorted(diffs.items(), key=lambda x: x[1], reverse=True))\n",
    "    prev_date = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.timeseries_df['count'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60638b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_threshold = 0.3\n",
    "\n",
    "for date, diffs in category_diffs.items():\n",
    "    print(f'Date: {date}')\n",
    "    print(f'Timeseries: {signal.loc[date][\"count\"]}')\n",
    "    for c, d in diffs.items():\n",
    "        if abs(d) > significance_threshold:\n",
    "            print(f'\\t{c}: {d:0.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386531e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a specific entity - what was going on when this entity trended in this feed?\n",
    "\n",
    "for s in signal.feeds_df.loc['2022-10-14']['stories']:\n",
    "    if any('Greece' in sf for sf in collect_sfs(s['entities'])):\n",
    "        print(f'Title: {s[\"title\"]}')\n",
    "        if entity_name in s['body']:\n",
    "            loc = s['body'].index(entity_name)\n",
    "            print(s['body'][loc-100:loc+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a specific category - what was going on when this category trended in this feed?\n",
    "\n",
    "for s in signal.feeds_df.loc['2022-10-09']['stories']:\n",
    "    if any('Private Banking' in c['label'] for c in s['categories']):\n",
    "        print(f'Title: {s[\"title\"]}')\n",
    "        if entity_name in s['body']:\n",
    "            loc = s['body'].index(entity_name)\n",
    "            print(s['body'][loc-100:loc+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669a9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
